"""
Gemini å›¾åƒç¼–è¾‘èŠ‚ç‚¹
æ”¯æŒå•å›¾å’Œå¤šå›¾è¾“å…¥ï¼Œè‡ªåŠ¨å¤„ç†æ‰¹æ¬¡æ•°æ®
"""

import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import json
import time
import random
from typing import Optional, Tuple, Dict, Any, List

try:
    from .tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    from .utils import (
        image_to_base64, base64_to_image,
        validate_api_key, format_error_message, resize_image_for_api
    )
    from .config import DEFAULT_CONFIG
except ImportError:
    from .tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    # Fallback utility functions - å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨å†…ç½®ç‰ˆæœ¬
    pass
    
    def image_to_base64(image, format='JPEG'):
        buffer = io.BytesIO()
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
            image = background
        image.save(buffer, format=format, quality=95)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def validate_api_key(api_key):
        return api_key and len(api_key.strip()) > 10
    
    def format_error_message(error):
        return str(error)
    
    DEFAULT_CONFIG = {"timeout": 120, "max_retries": 3}


def smart_retry_delay(attempt, error_code=None):
    """æ™ºèƒ½é‡è¯•å»¶è¿Ÿ"""
    base_delay = 2 ** attempt
    
    if error_code == 429:
        rate_limit_delay = 60 + random.uniform(10, 30)
        return max(base_delay, rate_limit_delay)
    elif error_code in [500, 502, 503, 504]:
        return base_delay + random.uniform(1, 5)
    else:
        return base_delay


class GeminiImageEdit:
    """Gemini å›¾åƒç¼–è¾‘èŠ‚ç‚¹ - ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†æ–¹å¼é¿å…ç™½è¾¹é—®é¢˜"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "Describe these images and edit them", "multiline": True}),
                "model": (["gemini-2.5-flash-image", "gemini-2.0-flash-preview-image-generation", "gemini-3-pro-image-preview"], {"default": "gemini-2.5-flash-image"}),
                "aspectRatio": ([
                    "auto",     # è‡ªåŠ¨é€‰æ‹©æœ€ä½³é•¿å®½æ¯”
                    "1:1",      # æ­£æ–¹å½¢
                    "9:16",     # ç«–å±
                    "16:9",     # æ¨ªå±
                    "3:4",      # ç«–å±
                    "4:3",      # æ¨ªå±
                    "3:2",      # æ¨ªå±
                    "2:3",      # ç«–å±
                    "5:4",      # æ¨ªå±
                    "4:5",      # ç«–å±
                    "21:9",     # è¶…å®½å±
                ], {"default": "auto"}),
                "image_size": (["1K", "2K", "4K"], {
                    "default": "4K",
                    "tooltip": "å›¾åƒåˆ†è¾¨ç‡ï¼ˆä»…é€‚ç”¨äº gemini-3-pro-image-preview æ¨¡å‹ï¼‰"
                }),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_output_tokens": ("INT", {"default": 8192, "min": 1, "max": 32768}),
            },
            "optional": {
                "images": ("IMAGE",),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
                "image_7": ("IMAGE",),
                "image_8": ("IMAGE",),
                "image_9": ("IMAGE",),
                "image_10": ("IMAGE",),
                "image_11": ("IMAGE",),
                "image_12": ("IMAGE",),
                "image_13": ("IMAGE",),
                "image_14": ("IMAGE",),
                "system_instruction": ("STRING", {"default": "", "multiline": True, "placeholder": "å¯é€‰ï¼šç³»ç»Ÿæç¤ºè¯ï¼Œä¸ºç©ºæ—¶ä¸å‘é€"}),
            }
        }
        
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("edited_image", "response_text")
    FUNCTION = "process_images"
    CATEGORY = "Nano"

    def process_images(self, api_key, prompt, model, aspectRatio="auto", image_size="4K", seed=0, temperature=1.0, top_p=0.95, max_output_tokens=8192, system_instruction="", 
                      images=None, image_1=None, image_2=None, image_3=None, image_4=None, image_5=None, image_6=None,
                      image_7=None, image_8=None, image_9=None, image_10=None, image_11=None, image_12=None, image_13=None, image_14=None):
        """å¤„ç†å›¾åƒå¹¶è¿”å›ç¼–è¾‘åçš„å›¾åƒå’Œå“åº”æ–‡æœ¬"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not api_key:
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„Gemini APIå¯†é’¥")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒ
        pil_images = []
        
        # å¤„ç†æ‰¹æ¬¡å›¾åƒï¼ˆå‘åå…¼å®¹ï¼‰
        if images is not None:
            batch_images = [tensor_to_pil(images[i]) for i in range(images.shape[0])]
            pil_images.extend(batch_images)
            print(f"ğŸ“¥ ä»æ‰¹æ¬¡å›¾åƒæ”¶åˆ° {len(batch_images)} å¼ å›¾åƒ")
        
        # å¤„ç†14ä¸ªç‹¬ç«‹çš„å›¾åƒè¾“å…¥
        individual_images = [image_1, image_2, image_3, image_4, image_5, image_6, 
                            image_7, image_8, image_9, image_10, image_11, image_12, image_13, image_14]
        image_names = ["image_1", "image_2", "image_3", "image_4", "image_5", "image_6",
                      "image_7", "image_8", "image_9", "image_10", "image_11", "image_12", "image_13", "image_14"]
        
        for i, img in enumerate(individual_images):
            if img is not None:
                pil_image = tensor_to_pil(img)
                pil_images.append(pil_image)
                print(f"ğŸ“¥ æ”¶åˆ° {image_names[i]}: {pil_image.size}")
        
        if not pil_images:
            raise ValueError("è¯·è‡³å°‘æä¾›ä¸€å¼ å›¾åƒ")
        
        print(f"ğŸ“¥ æ€»å…±æ”¶åˆ° {len(pil_images)} å¼ å›¾åƒè¿›è¡Œå¤„ç†")
        
        # æ£€æŸ¥å›¾ç‰‡æ•°é‡é™åˆ¶ï¼ˆgemini-3-pro-image-preview æ”¯æŒæœ€å¤š14å¼ å›¾ç‰‡ï¼‰
        if model == "gemini-3-pro-image-preview":
            if len(pil_images) > 14:
                print(f"âš ï¸ è­¦å‘Š: gemini-3-pro-image-preview æ¨¡å‹æœ€å¤šæ”¯æŒ14å¼ å›¾ç‰‡ï¼Œå½“å‰æœ‰ {len(pil_images)} å¼ ï¼Œå°†åªå¤„ç†å‰14å¼ ")
                pil_images = pil_images[:14]
            elif len(pil_images) == 14:
                print(f"âœ… ä½¿ç”¨ gemini-3-pro-image-preview æ¨¡å‹å¤„ç†14å¼ å›¾ç‰‡ï¼ˆæœ€å¤§æ”¯æŒæ•°é‡ï¼‰")
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†æ¨¡å¼å¤„ç†å›¾åƒ
        print(f"ğŸ”„ ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†æ¨¡å¼å¤„ç†å›¾åƒ")
        print(f"â„¹ï¸ Received seed {seed}, but the Gemini API does not currently support a seed parameter for image editing.")
        print(f"ğŸ“ ä½¿ç”¨é•¿å®½æ¯”: {aspectRatio}")
        if model == "gemini-3-pro-image-preview":
            print(f"ğŸ“ ä½¿ç”¨å›¾åƒåˆ†è¾¨ç‡: {image_size}")
        edited_tensor, response_text = self._process_combined_images(api_key, pil_images, prompt, model, aspectRatio, image_size, temperature, top_p, max_output_tokens, system_instruction)
        
        return (edited_tensor, response_text)
    
    def _process_combined_images(self, api_key: str, pil_images: List[Image.Image], prompt: str, model: str, aspectRatio: str, image_size: str,                                                                                         
                                temperature: float, top_p: float, max_output_tokens: int, system_instruction: str = "") -> Tuple[torch.Tensor, str]:
        """å¤„ç†å¤šå¼ å›¾åƒï¼ˆåˆå¹¶å‘é€ï¼‰"""
        
        # æ„å»ºåŒ…å«å¤šå¼ å›¾åƒçš„è¯·æ±‚
        parts = [{"text": prompt.strip()}]
        
        # æ·»åŠ æ‰€æœ‰å›¾åƒ
        for i, pil_image in enumerate(pil_images):
            image_base64 = image_to_base64(pil_image, format='JPEG')
            parts.append({
                "inline_data": {
                    "mime_type": "image/jpeg",
                    "data": image_base64
                }
            })
            print(f"ğŸ“ æ·»åŠ ç¬¬ {i+1} å¼ å›¾åƒåˆ°è¯·æ±‚ä¸­")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©APIç«¯ç‚¹å’Œé…ç½®æ ¼å¼
        is_gemini_3_pro = (model == "gemini-3-pro-image-preview")
        
        # æ„å»ºAPI URL - gemini-3-pro-image-preview ä½¿ç”¨ streamGenerateContent
        if is_gemini_3_pro:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:streamGenerateContent"
        else:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        # æ„å»ºè¯·æ±‚æ•°æ® - æ›´æ–°ä¸ºåŒ¹é…å®˜æ–¹ç¤ºä¾‹çš„æ ¼å¼
        generation_config = {
            "temperature": temperature,
            "topP": top_p,
            "maxOutputTokens": max_output_tokens,
            "responseModalities": ["IMAGE", "TEXT"]
        }
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®å›¾åƒé…ç½®
        if is_gemini_3_pro:
            # gemini-3-pro-image-preview åŒæ—¶æ”¯æŒ aspectRatio å’Œ image_size
            image_config = {
                "image_size": image_size
            }
            if aspectRatio != "auto":
                image_config["aspectRatio"] = aspectRatio
            generation_config["imageConfig"] = image_config
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨ aspectRatio
            if aspectRatio != "auto":
                generation_config["imageConfig"] = {
                    "aspectRatio": aspectRatio
                }
        
        request_data = {
            "contents": [{
                "parts": parts
            }],
            "generationConfig": generation_config
        }
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœæä¾›ï¼‰
        if system_instruction and system_instruction.strip():
            request_data["systemInstruction"] = {
                "parts": [{"text": system_instruction.strip()}]
            }
        
        # è®¾ç½®è¯·æ±‚å¤´ - gemini-3-pro-image-preview ä½¿ç”¨ key å‚æ•°è€Œä¸æ˜¯ x-goog-api-key
        if is_gemini_3_pro:
            url_with_key = f"{url}?key={api_key.strip()}"
            headers = {
                "Content-Type": "application/json"
            }
        else:
            url_with_key = url
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": api_key.strip()
            }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_request_and_process(url_with_key, headers, request_data, pil_images[0], model, is_gemini_3_pro)
    
    def _parse_stream_response(self, response):
        """è§£ææµå¼å“åº”ï¼ˆstreamGenerateContentï¼‰"""
        # æµå¼å“åº”é€šå¸¸æ˜¯ JSON Lines æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡
        # ä½†æ ¹æ® API æ–‡æ¡£ï¼Œä¹Ÿå¯èƒ½è¿”å›å•ä¸ª JSON å¯¹è±¡æˆ–æ•°ç»„
        try:
            # å°è¯•è§£æä¸ºå•ä¸ª JSON
            result = response.json()
            
            # å¦‚æœç»“æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            if isinstance(result, list):
                print(f"ğŸ“¦ è§£æä¸ºJSONæ•°ç»„ï¼Œé•¿åº¦: {len(result)}")
                if result:
                    result = result[0]
                    print(f"ğŸ“¦ ä½¿ç”¨æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œkeys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                else:
                    print(f"âš ï¸ JSONæ•°ç»„ä¸ºç©º")
                    return {"candidates": []}
            else:
                print(f"ğŸ“¦ è§£æä¸ºå•ä¸ªJSONå¯¹è±¡ï¼Œkeys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
            
            return result
        except:
            # å¦‚æœæ˜¯æµå¼å“åº”ï¼Œè§£ææ¯ä¸€è¡Œ
            lines = response.text.strip().split('\n')
            print(f"ğŸ“¦ è§£ææµå¼å“åº”ï¼Œå…± {len(lines)} è¡Œ")
            final_result = {"candidates": []}
            
            for line_idx, line in enumerate(lines):
                if line.strip():
                    try:
                        chunk = json.loads(line)
                        
                        # å¦‚æœchunkæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        if isinstance(chunk, list):
                            if chunk:
                                chunk = chunk[0]
                            else:
                                continue
                        
                        print(f"ğŸ“¦ ç¬¬ {line_idx + 1} è¡Œ: keys={list(chunk.keys()) if isinstance(chunk, dict) else 'N/A'}")
                        
                        # åˆå¹¶æµå¼å“åº”çš„æ•°æ®
                        if "candidates" in chunk:
                            if not final_result["candidates"]:
                                final_result["candidates"] = chunk["candidates"]
                                print(f"ğŸ“¦ åˆå§‹åŒ– candidatesï¼Œæ•°é‡: {len(final_result['candidates'])}")
                            else:
                                # åˆå¹¶å€™é€‰å†…å®¹
                                for i, candidate in enumerate(chunk["candidates"]):
                                    if i < len(final_result["candidates"]):
                                        if "content" in candidate and "parts" in candidate["content"]:
                                            if "content" not in final_result["candidates"][i]:
                                                final_result["candidates"][i]["content"] = {"parts": []}
                                            parts_count = len(candidate["content"]["parts"])
                                            final_result["candidates"][i]["content"]["parts"].extend(candidate["content"]["parts"])
                                            print(f"ğŸ“¦ åˆå¹¶ candidate[{i}]ï¼Œæ·»åŠ  {parts_count} ä¸ª parts")
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ ç¬¬ {line_idx + 1} è¡ŒJSONè§£æå¤±è´¥: {e}")
                        continue
            
            print(f"ğŸ“¦ æœ€ç»ˆç»“æœ: candidatesæ•°é‡={len(final_result.get('candidates', []))}")
            return final_result if final_result["candidates"] else {"candidates": []}
    
    def _send_request_and_process(self, url: str, headers: dict, request_data: dict, 
                                 fallback_image: Image.Image, model: str, is_stream: bool = False) -> Tuple[torch.Tensor, str]:
        """å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ–¼ï¸ æ­£åœ¨å¤„ç†å›¾åƒ... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    # å¤„ç†æµå¼å“åº”ï¼ˆgemini-3-pro-image-previewï¼‰
                    if is_stream:
                        result = self._parse_stream_response(response)
                    else:
                        result = response.json()
                        # å¦‚æœç»“æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        if isinstance(result, list):
                            print(f"ğŸ“‹ å“åº”æ˜¯æ•°ç»„ï¼Œé•¿åº¦: {len(result)}")
                            if result:
                                result = result[0]
                            else:
                                result = {"candidates": []}
                    
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys()) if isinstance(result, dict) else type(result).__name__}")
                    
                    # æå–æ–‡æœ¬å“åº”å’Œç¼–è¾‘åçš„å›¾ç‰‡
                    response_text = ""
                    edited_image = None
                    
                    if isinstance(result, dict) and "candidates" in result and result["candidates"]:
                        candidate = result["candidates"][0]
                        print(f"ğŸ“‹ Candidateç»“æ„: {list(candidate.keys()) if isinstance(candidate, dict) else 'N/A'}")
                        
                        if "content" in candidate and "parts" in candidate["content"]:
                            parts = candidate["content"]["parts"]
                            print(f"ğŸ“‹ æ‰¾åˆ° {len(parts)} ä¸ª parts")
                            
                            for part_idx, part in enumerate(parts):
                                print(f"ğŸ“‹ Part[{part_idx}] keys: {list(part.keys()) if isinstance(part, dict) else 'N/A'}")
                                
                                # æå–æ–‡æœ¬
                                if "text" in part:
                                    text_content = part["text"]
                                    response_text += text_content
                                    print(f"ğŸ“‹ Part[{part_idx}] åŒ…å«æ–‡æœ¬ï¼Œé•¿åº¦: {len(text_content)}")
                                
                                # æå–ç¼–è¾‘åçš„å›¾ç‰‡ - æ£€æŸ¥å¤šç§å¯èƒ½çš„å­—æ®µå
                                inline_data = None
                                if "inline_data" in part:
                                    inline_data = part["inline_data"]
                                    print(f"ğŸ“‹ Part[{part_idx}] åŒ…å« inline_data")
                                elif "inlineData" in part:
                                    inline_data = part["inlineData"]
                                    print(f"ğŸ“‹ Part[{part_idx}] åŒ…å« inlineData")
                                
                                if inline_data:
                                    print(f"ğŸ“‹ inline_data keys: {list(inline_data.keys()) if isinstance(inline_data, dict) else 'N/A'}")
                                    if "data" in inline_data:
                                        try:
                                            image_data = inline_data["data"]
                                            mime_type = inline_data.get("mimeType", "unknown")
                                            print(f"ğŸ“‹ æ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼ŒmimeType: {mime_type}, æ•°æ®é•¿åº¦: {len(image_data)}")
                                            image_bytes = base64.b64decode(image_data)
                                            edited_image = Image.open(io.BytesIO(image_bytes))
                                            print(f"âœ… æˆåŠŸæå–ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œå°ºå¯¸: {edited_image.size}")
                                        except Exception as e:
                                            print(f"âš ï¸ è§£ç å›¾ç‰‡å¤±è´¥: {e}")
                                            import traceback
                                            print(f"âš ï¸ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                        else:
                            print(f"âš ï¸ Candidateä¸­æ²¡æœ‰content.partsï¼Œcandidate keys: {list(candidate.keys())}")
                            # å°è¯•ç›´æ¥æ£€æŸ¥candidateä¸­æ˜¯å¦æœ‰å›¾ç‰‡æ•°æ®
                            if "inline_data" in candidate or "inlineData" in candidate:
                                inline_data = candidate.get("inline_data") or candidate.get("inlineData")
                                if inline_data and "data" in inline_data:
                                    try:
                                        image_data = inline_data["data"]
                                        image_bytes = base64.b64decode(image_data)
                                        edited_image = Image.open(io.BytesIO(image_bytes))
                                        print("âœ… æˆåŠŸä»candidateç›´æ¥æå–ç¼–è¾‘åçš„å›¾ç‰‡")
                                    except Exception as e:
                                        print(f"âš ï¸ ä»candidateè§£ç å›¾ç‰‡å¤±è´¥: {e}")
                    else:
                        print(f"âš ï¸ å“åº”ä¸­æ²¡æœ‰candidatesï¼Œresultç±»å‹: {type(result).__name__}")
                        if isinstance(result, dict):
                            print(f"âš ï¸ result keys: {list(result.keys())}")
                        elif isinstance(result, list):
                            print(f"âš ï¸ resultæ˜¯æ•°ç»„ï¼Œé•¿åº¦: {len(result)}")
                            if result:
                                print(f"âš ï¸ æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(result[0]).__name__}")
                                if isinstance(result[0], dict):
                                    print(f"âš ï¸ æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´ keys: {list(result[0].keys())}")
                        # æ‰“å°å®Œæ•´çš„å“åº”ç»“æ„ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
                        try:
                            debug_str = json.dumps(result, indent=2, ensure_ascii=False)[:1000]
                            print(f"ğŸ“‹ å“åº”å†…å®¹é¢„è§ˆ: {debug_str}...")
                        except:
                            print(f"ğŸ“‹ æ— æ³•åºåˆ—åŒ–å“åº”å†…å®¹")
                    
                    # å¦‚æœæ²¡æœ‰ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡
                    if edited_image is None:
                        print("âš ï¸ æœªæ£€æµ‹åˆ°ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡")
                        edited_image = fallback_image
                        if not response_text:
                            response_text = "å›¾ç‰‡å¤„ç†è¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°ç¼–è¾‘åçš„å›¾ç‰‡"
                    
                    # è½¬æ¢ä¸ºtensor
                    image_tensor = pil_to_tensor(edited_image)
                    
                    print("âœ… å›¾ç‰‡å¤„ç†å®Œæˆ")
                    return (image_tensor, response_text)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                    except:
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {response.text}")
                    
                    if attempt == max_retries - 1:
                        response.raise_for_status()
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {error_msg}")


class GeminiImageGenerate:
    """Gemini å›¾åƒç”ŸæˆèŠ‚ç‚¹ - æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒ"""
    
    def _parse_stream_response_generate(self, response):
        """è§£æç”ŸæˆèŠ‚ç‚¹çš„æµå¼å“åº”ï¼ˆstreamGenerateContentï¼‰"""
        # æµå¼å“åº”é€šå¸¸æ˜¯ JSON Lines æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡
        # ä½†æ ¹æ® API æ–‡æ¡£ï¼Œä¹Ÿå¯èƒ½è¿”å›å•ä¸ª JSON å¯¹è±¡æˆ–æ•°ç»„
        try:
            # å°è¯•è§£æä¸ºå•ä¸ª JSON
            result = response.json()
            
            # å¦‚æœç»“æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            if isinstance(result, list):
                if result:
                    result = result[0]
                else:
                    return {"candidates": []}
            
            return result
        except:
            # å¦‚æœæ˜¯æµå¼å“åº”ï¼Œè§£ææ¯ä¸€è¡Œ
            lines = response.text.strip().split('\n')
            final_result = {"candidates": []}
            
            for line in lines:
                if line.strip():
                    try:
                        chunk = json.loads(line)
                        
                        # å¦‚æœchunkæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        if isinstance(chunk, list):
                            if chunk:
                                chunk = chunk[0]
                            else:
                                continue
                        
                        # åˆå¹¶æµå¼å“åº”çš„æ•°æ®
                        if "candidates" in chunk:
                            if not final_result["candidates"]:
                                final_result["candidates"] = chunk["candidates"]
                            else:
                                # åˆå¹¶å€™é€‰å†…å®¹
                                for i, candidate in enumerate(chunk["candidates"]):
                                    if i < len(final_result["candidates"]):
                                        if "content" in candidate and "parts" in candidate["content"]:
                                            if "content" not in final_result["candidates"][i]:
                                                final_result["candidates"][i]["content"] = {"parts": []}
                                            final_result["candidates"][i]["content"]["parts"].extend(candidate["content"]["parts"])
                    except json.JSONDecodeError:
                        continue
            
            return final_result if final_result["candidates"] else {"candidates": []}
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme", "multiline": True}),
                "model": (["gemini-2.5-flash-image", "gemini-2.0-flash-preview-image-generation", "gemini-3-pro-image-preview"], {"default": "gemini-2.5-flash-image"}),
                "aspectRatio": ([
                    "auto",     # è‡ªåŠ¨é€‰æ‹©æœ€ä½³é•¿å®½æ¯”
                    "1:1",      # æ­£æ–¹å½¢
                    "9:16",     # ç«–å±
                    "16:9",     # æ¨ªå±
                    "3:4",      # ç«–å±
                    "4:3",      # æ¨ªå±
                    "3:2",      # æ¨ªå±
                    "2:3",      # ç«–å±
                    "5:4",      # æ¨ªå±
                    "4:5",      # ç«–å±
                    "21:9",     # è¶…å®½å±
                ], {"default": "auto"}),
                "image_size": (["1K", "2K", "4K"], {
                    "default": "4K",
                    "tooltip": "å›¾åƒåˆ†è¾¨ç‡ï¼ˆä»…é€‚ç”¨äº gemini-3-pro-image-preview æ¨¡å‹ï¼‰"
                }),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_output_tokens": ("INT", {"default": 2048, "min": 1, "max": 8192}),
            },
            "optional": {
                "system_instruction": ("STRING", {"default": "", "multiline": True, "placeholder": "å¯é€‰ï¼šç³»ç»Ÿæç¤ºè¯ï¼Œä¸ºç©ºæ—¶ä¸å‘é€"}),
            }
        }
        
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("generated_image", "response_text")
    FUNCTION = "generate_images"
    CATEGORY = "Nano"

    def generate_images(self, api_key: str, prompt: str, model: str, aspectRatio: str, image_size: str, seed: int,
                        temperature: float, top_p: float, max_output_tokens: int, system_instruction: str = "") -> Tuple[torch.Tensor, str]:
        
        if not validate_api_key(api_key):
            raise ValueError("API Keyæ ¼å¼æ— æ•ˆæˆ–ä¸ºç©º")
        
        if not prompt.strip():
            raise ValueError("æç¤ºè¯ä¸èƒ½ä¸ºç©º")

        print(f"â„¹ï¸ Received seed {seed}, but the Gemini API does not currently support a seed parameter for image generation.")
        print(f"ğŸ“ ä½¿ç”¨é•¿å®½æ¯”: {aspectRatio}")
        if model == "gemini-3-pro-image-preview":
            print(f"ğŸ“ ä½¿ç”¨å›¾åƒåˆ†è¾¨ç‡: {image_size}")

        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©APIç«¯ç‚¹
        is_gemini_3_pro = (model == "gemini-3-pro-image-preview")
        
        if is_gemini_3_pro:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:streamGenerateContent"
        else:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        generation_config = {
            "candidateCount": 1,
            "temperature": temperature,
            "topP": top_p,
            "maxOutputTokens": max_output_tokens,
            "responseModalities": ["IMAGE", "TEXT"]
        }
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®å›¾åƒé…ç½®
        if is_gemini_3_pro:
            # gemini-3-pro-image-preview åŒæ—¶æ”¯æŒ aspectRatio å’Œ image_size
            image_config = {
                "image_size": image_size
            }
            if aspectRatio != "auto":
                image_config["aspectRatio"] = aspectRatio
            generation_config["imageConfig"] = image_config
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨ aspectRatio
            if aspectRatio != "auto":
                generation_config["imageConfig"] = {
                    "aspectRatio": aspectRatio
                }
        
        request_data = {
            "contents": [{
                "parts": [
                    {"text": prompt.strip()}
                ]
            }],
            "generationConfig": generation_config
        }
        
        # åªæœ‰å½“ç³»ç»Ÿæç¤ºè¯ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ  systemInstruction
        if system_instruction and system_instruction.strip():
            request_data["systemInstruction"] = {
                "parts": [
                    {"text": system_instruction.strip()}
                ]
            }
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®è¯·æ±‚å¤´å’ŒURL
        if is_gemini_3_pro:
            url_with_key = f"{url}?key={api_key.strip()}"
            headers = {
                "Content-Type": "application/json"
            }
        else:
            url_with_key = url
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": api_key.strip()
            }
        
        return self._send_request_and_generate_images(url_with_key, headers, request_data, model, is_gemini_3_pro)

    def _send_request_and_generate_images(self, url: str, headers: dict, request_data: dict, model: str, is_stream: bool = False) -> Tuple[torch.Tensor, str]:
        """å‘é€ç”Ÿæˆè¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾åƒ... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                if response.status_code == 200:
                    # å¤„ç†æµå¼å“åº”ï¼ˆgemini-3-pro-image-previewï¼‰
                    if is_stream:
                        result = self._parse_stream_response_generate(response)
                    else:
                        result = response.json()
                        # å¦‚æœç»“æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                        if isinstance(result, list):
                            print(f"ğŸ“‹ å“åº”æ˜¯æ•°ç»„ï¼Œé•¿åº¦: {len(result)}")
                            if result:
                                result = result[0]
                            else:
                                result = {"candidates": []}
                    generated_images = []
                    response_texts = []
                    
                    if isinstance(result, dict) and "candidates" in result and result["candidates"]:
                        for i, candidate in enumerate(result["candidates"]):
                            candidate_text = ""
                            candidate_image = None
                            if "content" in candidate and "parts" in candidate["content"]:
                                for part in candidate["content"]["parts"]:
                                    if "text" in part:
                                        candidate_text += part["text"]
                                    
                                    if "inline_data" in part or "inlineData" in part:
                                        inline_data = part.get("inline_data") or part.get("inlineData")
                                        if inline_data and "data" in inline_data:
                                            try:
                                                image_data = inline_data["data"]
                                                image_bytes = base64.b64decode(image_data)
                                                candidate_image = Image.open(io.BytesIO(image_bytes))
                                            except Exception as e:
                                                print(f"âš ï¸ è§£ç å€™é€‰å›¾ç‰‡ {i+1} å¤±è´¥: {e}")
                            
                            if candidate_image:
                                generated_images.append(candidate_image)
                                response_texts.append(f"å›¾åƒ {i+1}:\n{candidate_text}")
                                print(f"âœ… æˆåŠŸæå–ç”Ÿæˆçš„å›¾ç‰‡ {i+1}")

                    if not generated_images:
                        raise ValueError("APIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç”Ÿæˆå›¾ç‰‡")
                    
                    if len(generated_images) == 1:
                        final_tensor = pil_to_tensor(generated_images[0])
                    else:
                        tensors = [pil_to_tensor(img) for img in generated_images]
                        final_tensor = torch.stack(tensors, dim=0)
                    
                    combined_response = "\n\n".join(response_texts)
                    print(f"âœ… å›¾åƒç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºå¼ é‡å½¢çŠ¶: {final_tensor.shape}")
                    return (final_tensor, combined_response)
                
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                    except:
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {response.text}")
                    
                    if attempt == max_retries - 1:
                        response.raise_for_status()
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
            
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
                raise ValueError(f"å›¾åƒç”Ÿæˆå¤±è´¥: {error_msg}")


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "GeminiImageEdit": GeminiImageEdit,
    "GeminiImageGenerate": GeminiImageGenerate,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiImageEdit": "Gemini å›¾åƒç¼–è¾‘",
    "GeminiImageGenerate": "Gemini å›¾åƒç”Ÿæˆ",
}