"""
Comfly AI é•œåƒç«™èŠ‚ç‚¹
å…¼å®¹Gemini APIæ ¼å¼ï¼Œä½†ä½¿ç”¨Comflyé•œåƒæœåŠ¡åœ°å€
"""

import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import json
import time
import random
from typing import Optional, Tuple, Dict, Any, List

try:
    from .tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    from .utils import (
        image_to_base64, base64_to_image,
        validate_api_key, format_error_message, resize_image_for_api
    )
    from .config import DEFAULT_CONFIG
except ImportError:
    # ä¿®å¤å¯¼å…¥è·¯å¾„ï¼Œä¸ä½¿ç”¨å‰ç¼€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨comfyui_nanoåŒ…ä¸­
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    try:
        from tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    except ImportError:
        print("âš ï¸ æ— æ³•å¯¼å…¥tensor_utilsæ¨¡å—ï¼Œä½¿ç”¨å†…ç½®ç®€åŒ–ç‰ˆæœ¬")
        # ç®€åŒ–ç‰ˆtensorè½¬æ¢å‡½æ•°
        def tensor_to_pil(tensor):
            """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
            tensor = tensor.cpu().detach().numpy()
            # å°†tensorçš„ç»´åº¦ä»[C, H, W]è½¬æ¢ä¸º[H, W, C]
            tensor = tensor.transpose(1, 2, 0)
            # ç¡®ä¿å€¼çš„èŒƒå›´æ˜¯0-1
            tensor = tensor * 255
            tensor = np.clip(tensor, 0, 255).astype(np.uint8)
            # åˆ›å»ºPILå›¾åƒ
            return Image.fromarray(tensor)
        
        def pil_to_tensor(pil_image):
            """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor"""
            # ç¡®ä¿å›¾åƒæ˜¯RGBæ¨¡å¼
            if pil_image.mode != "RGB":
                pil_image = pil_image.convert("RGB")
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            np_image = np.array(pil_image).astype(np.float32) / 255.0
            # è½¬æ¢ä¸º[C, H, W]æ ¼å¼
            np_image = np_image.transpose(2, 0, 1)
            # åˆ›å»ºtensor
            return torch.from_numpy(np_image)
        
        def batch_tensor_to_pil_list(batch_tensor):
            """å°†æ‰¹æ¬¡tensorè½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨"""
            return [tensor_to_pil(batch_tensor[i]) for i in range(batch_tensor.shape[0])]
        
        def get_tensor_info(tensor):
            """è·å–tensorçš„ä¿¡æ¯"""
            shape = tensor.shape
            return f"å½¢çŠ¶:{shape}, ç±»å‹:{tensor.dtype}, è®¾å¤‡:{tensor.device}, æœ€å°å€¼:{tensor.min().item():.4f}, æœ€å¤§å€¼:{tensor.max().item():.4f}"
    
    # Fallback utility functions - å…¶ä»–è¾…åŠ©å‡½æ•°çš„ç®€åŒ–ç‰ˆæœ¬
    def image_to_base64(image, format='JPEG'):
        buffer = io.BytesIO()
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
            image = background
        image.save(buffer, format=format, quality=95)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def base64_to_image(base64_string):
        """Base64å­—ç¬¦ä¸²è½¬PILå›¾åƒ"""
        image_data = base64.b64decode(base64_string)
        return Image.open(io.BytesIO(image_data))
    
    def validate_api_key(api_key):
        return api_key and len(api_key.strip()) > 10
    
    def format_error_message(error):
        return str(error)
    
    def resize_image_for_api(image, max_size=4000):
        """è°ƒæ•´å›¾åƒå¤§å°ä»¥æ»¡è¶³APIé™åˆ¶"""
        width, height = image.size
        if width <= max_size and height <= max_size:
            return image
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = min(max_size / width, max_size / height)
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    
    DEFAULT_CONFIG = {"timeout": 120, "max_retries": 3}


def smart_retry_delay(attempt, error_code=None):
    """æ™ºèƒ½é‡è¯•å»¶è¿Ÿ"""
    base_delay = 2 ** attempt
    
    if error_code == 429:
        rate_limit_delay = 60 + random.uniform(10, 30)
        return max(base_delay, rate_limit_delay)
    elif error_code in [500, 502, 503, 504]:
        return base_delay + random.uniform(1, 5)
    else:
        return base_delay


class ComflyGeminiMirror:
    """Comflyé•œåƒç«™ Gemini å›¾åƒç¼–è¾‘ä¸ç”ŸæˆèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "æè¿°å¹¶ç¼–è¾‘è¿™äº›å›¾åƒï¼Œæˆ–è€…ç”Ÿæˆæ–°å›¾åƒ", "multiline": True}),
                "model": (["gemini-2.5-flash-image-preview", "gemini-2.0-flash-preview-image-generation"], {"default": "gemini-2.5-flash-image-preview"}),
                "mode": (["edit", "generate"], {"default": "edit"}),  # ç¼–è¾‘æˆ–ç”Ÿæˆæ¨¡å¼
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_output_tokens": ("INT", {"default": 8192, "min": 1, "max": 32768}),
            },
            "optional": {
                "images": ("IMAGE",),
            }
        }
        
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("output_image", "response_text")
    FUNCTION = "process"
    CATEGORY = "Nano"

    def process(self, api_key, prompt, model, mode, seed=0, temperature=1.0, top_p=0.95, max_output_tokens=8192, images=None):
        """å¤„ç†è¯·æ±‚ï¼Œæ ¹æ®æ¨¡å¼è¿›è¡Œç¼–è¾‘æˆ–ç”Ÿæˆ"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„APIå¯†é’¥")
        
        # æ ¹æ®æ¨¡å¼å†³å®šå¤„ç†æ–¹æ³•
        if mode == "edit":
            if images is None:
                raise ValueError("ç¼–è¾‘æ¨¡å¼ä¸‹éœ€è¦æä¾›è¾“å…¥å›¾åƒ")
            return self._process_edit(api_key, images, prompt, model, seed, temperature, top_p, max_output_tokens)
        else:  # generate
            return self._process_generate(api_key, prompt, model, seed, temperature, top_p, max_output_tokens)
    
    def _process_edit(self, api_key, images, prompt, model, seed, temperature, top_p, max_output_tokens):
        """å¤„ç†å›¾åƒç¼–è¾‘è¯·æ±‚"""
        
        # å°†æ‰¹æ¬¡å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨
        pil_images = [tensor_to_pil(images[i]) for i in range(images.shape[0])]
        print(f"ğŸ“¥ æ”¶åˆ° {len(pil_images)} å¼ å›¾åƒè¿›è¡Œç¼–è¾‘")
        
        # æ„å»ºåŒ…å«å¤šå¼ å›¾åƒçš„è¯·æ±‚
        parts = [{"text": prompt.strip()}]
        
        # æ·»åŠ æ‰€æœ‰å›¾åƒ
        for i, pil_image in enumerate(pil_images):
            image_base64 = image_to_base64(pil_image, format='JPEG')
            parts.append({
                "inline_data": {
                    "mime_type": "image/jpeg",
                    "data": image_base64
                }
            })
            print(f"ğŸ“ æ·»åŠ ç¬¬ {i+1} å¼ å›¾åƒåˆ°è¯·æ±‚ä¸­")
        
        # æ„å»ºAPI URL - ä½¿ç”¨Comflyé•œåƒç«™åœ°å€
        url = f"https://ai.comfly.chat/v1beta/models/{model}:generateContent"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "contents": [{
                "parts": parts
            }],
            "generationConfig": {
                "temperature": temperature,
                "topP": top_p,
                "maxOutputTokens": max_output_tokens
            }
        }
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": api_key.strip()
        }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_request_and_process(url, headers, request_data, pil_images[0], model)
    
    def _process_generate(self, api_key, prompt, model, seed, temperature, top_p, max_output_tokens):
        """å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚"""
        
        if not prompt.strip():
            raise ValueError("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
        
        print(f"â„¹ï¸ ä½¿ç”¨ç§å­ {seed}, ä½†æ³¨æ„ Gemini API å½“å‰ä¸æ”¯æŒç§å­å‚æ•°")
        
        # æ„å»ºAPI URL - ä½¿ç”¨Comflyé•œåƒç«™åœ°å€
        url = f"https://ai.comfly.chat/v1beta/models/{model}:generateContent"
        
        request_data = {
            "contents": [{
                "parts": [
                    {"text": prompt.strip()}
                ]
            }],
            "generationConfig": {
                "candidateCount": 1,
                "temperature": temperature,
                "topP": top_p,
                "maxOutputTokens": max_output_tokens
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": api_key.strip()
        }
        
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤å›¾åƒä½œä¸ºfallback
        default_image = Image.new('RGB', (512, 512), (0, 0, 0))
        
        return self._send_request_and_process(url, headers, request_data, default_image, model)
    
    def _send_request_and_process(self, url, headers, request_data, fallback_image, model):
        """å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ–¼ï¸ æ­£åœ¨å¤„ç†è¯·æ±‚... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ ä½¿ç”¨Comflyé•œåƒç«™: {url}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–æ–‡æœ¬å“åº”å’Œå›¾ç‰‡
                    response_text = ""
                    processed_images = []
                    
                    if "candidates" in result and result["candidates"]:
                        for candidate in result["candidates"]:
                            if "content" in candidate and "parts" in candidate["content"]:
                                for part in candidate["content"]["parts"]:
                                    # æå–æ–‡æœ¬
                                    if "text" in part:
                                        response_text += part["text"]
                                    
                                    # æå–å›¾ç‰‡
                                    if "inline_data" in part or "inlineData" in part:
                                        inline_data = part.get("inline_data") or part.get("inlineData")
                                        if inline_data and "data" in inline_data:
                                            try:
                                                image_data = inline_data["data"]
                                                image_bytes = base64.b64decode(image_data)
                                                processed_image = Image.open(io.BytesIO(image_bytes))
                                                processed_images.append(processed_image)
                                                print("âœ… æˆåŠŸæå–å›¾ç‰‡")
                                            except Exception as e:
                                                print(f"âš ï¸ è§£ç å›¾ç‰‡å¤±è´¥: {e}")
                    
                    # å¦‚æœæ²¡æœ‰å¤„ç†åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡
                    if not processed_images:
                        print("âš ï¸ æœªæ£€æµ‹åˆ°ç”Ÿæˆ/ç¼–è¾‘åçš„å›¾ç‰‡ï¼Œè¿”å›åŸå›¾ç‰‡")
                        processed_images.append(fallback_image)
                        if not response_text:
                            response_text = "è¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°ç”Ÿæˆ/ç¼–è¾‘åçš„å›¾ç‰‡"
                    
                    # è½¬æ¢ä¸ºtensor
                    if len(processed_images) == 1:
                        image_tensor = pil_to_tensor(processed_images[0])
                    else:
                        # å¤šå¼ å›¾ç‰‡æ—¶ï¼Œåˆ›å»ºæ‰¹æ¬¡tensor
                        tensors = [pil_to_tensor(img) for img in processed_images]
                        image_tensor = torch.stack(tensors, dim=0)
                    
                    print(f"âœ… å¤„ç†å®Œæˆï¼Œè¾“å‡ºå¼ é‡å½¢çŠ¶: {image_tensor.shape}")
                    return (image_tensor, response_text)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                    except:
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {response.text}")
                    
                    if attempt == max_retries - 1:
                        response.raise_for_status()
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤„ç†å¤±è´¥: {error_msg}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ComflyGeminiMirror": ComflyGeminiMirror,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ComflyGeminiMirror": "Comflyé•œåƒç«™",
} 