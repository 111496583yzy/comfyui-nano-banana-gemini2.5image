"""
å›¾åƒå¤„ç†èŠ‚ç‚¹
åŒ…å«é«˜åå·®ä¿ç•™ç­‰å›¾åƒå¢å¼ºåŠŸèƒ½
"""

import torch
import numpy as np
from PIL import Image, ImageFilter
from typing import Tuple

try:
    from .tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info


class HighPassFilterNode:
    """
    PSé«˜åå·®ä¿ç•™èŠ‚ç‚¹
    å®ç°é«˜åå·®ä¿ç•™æ»¤é•œæ•ˆæœï¼Œç”¨äºå¢å¼ºå›¾åƒç»†èŠ‚å’Œå¯¹æ¯”åº¦
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),  # è¾“å…¥çš„å›¾åƒæ‰¹æ¬¡
                "radius": ("FLOAT", {
                    "default": 10.0,
                    "min": 0.1,
                    "max": 100.0,
                    "step": 0.1,
                    "tooltip": "é«˜æ–¯æ¨¡ç³ŠåŠå¾„ï¼Œæ§åˆ¶ä¿ç•™çš„ç»†èŠ‚èŒƒå›´"
                }),
                "amount": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.0,
                    "max": 5.0,
                    "step": 0.1,
                    "tooltip": "é«˜åå·®ä¿ç•™çš„å¼ºåº¦ï¼Œ0=æ— æ•ˆæœï¼Œ1=æ ‡å‡†æ•ˆæœï¼Œå¤§äº1=å¢å¼ºæ•ˆæœ"
                }),
                "blend_mode": (["normal", "overlay", "soft_light"], {
                    "default": "normal",
                    "tooltip": "æ··åˆæ¨¡å¼ï¼šnormal=æ­£å¸¸å åŠ ï¼Œoverlay=å åŠ æ¨¡å¼ï¼Œsoft_light=æŸ”å…‰æ¨¡å¼"
                })
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("high_pass_images",)
    FUNCTION = "apply_high_pass"
    CATEGORY = "Nano/å›¾åƒå¤„ç†"
    
    def apply_high_pass(self, images, radius, amount, blend_mode):
        """
        åº”ç”¨é«˜åå·®ä¿ç•™æ»¤é•œ
        
        Args:
            images: è¾“å…¥å›¾åƒæ‰¹æ¬¡ [B, H, W, C] æˆ– [B, C, H, W]
            radius: é«˜æ–¯æ¨¡ç³ŠåŠå¾„
            amount: é«˜åå·®å¼ºåº¦
            blend_mode: æ··åˆæ¨¡å¼
            
        Returns:
            å¤„ç†åçš„å›¾åƒæ‰¹æ¬¡
        """
        print(f"ğŸ”„ åº”ç”¨é«˜åå·®ä¿ç•™æ»¤é•œ: radius={radius}, amount={amount}, blend_mode={blend_mode}")
        
        # ç¡®ä¿è¾“å…¥æ˜¯tensoræ ¼å¼
        if isinstance(images, np.ndarray):
            images = torch.from_numpy(images)
        
        # å¤„ç†æ‰¹æ¬¡ç»´åº¦
        batch_size = images.shape[0]
        print(f"ğŸ“Š è¾“å…¥å›¾åƒæ‰¹æ¬¡å¤§å°: {batch_size}, å›¾åƒå½¢çŠ¶: {images.shape}")
        
        # è½¬æ¢tensorä¸ºPILå›¾åƒåˆ—è¡¨
        pil_images = batch_tensor_to_pil_list(images)
        
        processed_images = []
        
        for i, pil_image in enumerate(pil_images):
            try:
                # åº”ç”¨é«˜åå·®ä¿ç•™
                result = self._high_pass_filter(pil_image, radius, amount, blend_mode)
                processed_images.append(result)
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†ç¬¬ {i+1} å¼ å›¾åƒæ—¶å‡ºé”™: {e}")
                # å‡ºé”™æ—¶è¿”å›åŸå›¾
                processed_images.append(pil_image)
        
        # è½¬æ¢å›tensorå¹¶ä¿æŒæ­£ç¡®çš„æ‰¹æ¬¡æ ¼å¼
        result_tensors = []
        for img in processed_images:
            # pil_to_tensor è¿”å› (1, H, W, C)ï¼Œå»æ‰æ‰¹æ¬¡ç»´åº¦
            tensor = pil_to_tensor(img)
            result_tensors.append(tensor.squeeze(0))  # å»æ‰æ‰¹æ¬¡ç»´åº¦
        
        # å †å ä¸ºæ‰¹æ¬¡ (batch, H, W, C)
        result_batch = torch.stack(result_tensors, dim=0)
        
        print(f"âœ… é«˜åå·®ä¿ç•™å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ‰¹æ¬¡å¤§å°: {result_batch.shape}")
        return (result_batch,)
    
    def _high_pass_filter(self, image, radius, amount, blend_mode):
        """
        å¯¹å•å¼ å›¾åƒåº”ç”¨é«˜åå·®ä¿ç•™æ»¤é•œ
        
        ç®—æ³•åŸç†ï¼š
        1. åŸå›¾åƒ -> é«˜æ–¯æ¨¡ç³Š -> æ¨¡ç³Šå›¾
        2. åŸå›¾ - æ¨¡ç³Šå›¾ = ç»†èŠ‚å›¾
        3. åŸå›¾ + ç»†èŠ‚å›¾ * amount = æœ€ç»ˆç»“æœ
        """
        # è½¬æ¢ä¸ºRGBæ ¼å¼
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        blurred = image.filter(ImageFilter.GaussianBlur(radius=radius))
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œè®¡ç®—
        original = np.array(image, dtype=np.float32)
        blurred_array = np.array(blurred, dtype=np.float32)
        
        # è®¡ç®—é«˜åå·®ä¿ç•™ï¼šåŸå›¾ - æ¨¡ç³Šå›¾ = ç»†èŠ‚å›¾
        # å°†ç»†èŠ‚å åŠ åˆ°ä¸­ç°åº¦å€¼ä¸Š
        details = original - blurred_array + 128.0
        
        # åº”ç”¨å¼ºåº¦å‚æ•°
        # é€šè¿‡è°ƒæ•´åŸå›¾å’Œç»†èŠ‚å›¾çš„æ··åˆæ¯”ä¾‹æ¥å®ç°
        result = blurred_array + (details - blurred_array) * amount
        
        # é™åˆ¶åƒç´ å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
        result = np.clip(result, 0, 255).astype(np.uint8)
        
        # æ ¹æ®æ··åˆæ¨¡å¼è°ƒæ•´ç»“æœ
        if blend_mode == "normal":
            # æ­£å¸¸æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨é«˜åå·®ä¿ç•™ç»“æœ
            output = Image.fromarray(result)
        elif blend_mode == "overlay":
            # å åŠ æ¨¡å¼ï¼šæ¨¡æ‹ŸPSçš„overlayæ··åˆ
            output = self._blend_overlay(image, blurred, amount)
        elif blend_mode == "soft_light":
            # æŸ”å…‰æ¨¡å¼ï¼šæ›´æŸ”å’Œçš„æ··åˆæ•ˆæœ
            output = self._blend_soft_light(image, blurred, amount)
        else:
            output = Image.fromarray(result)
        
        return output
    
    def _blend_overlay(self, original, blurred, amount):
        """å åŠ æ··åˆæ¨¡å¼"""
        orig_array = np.array(original, dtype=np.float32)
        blur_array = np.array(blurred, dtype=np.float32)
        
        # è®¡ç®—é«˜åå·®ä¿ç•™
        high_pass = orig_array - blur_array + 128.0
        high_pass = np.clip(high_pass, 0, 255)
        
        # å åŠ æ··åˆå…¬å¼
        mask = (orig_array < 128).astype(np.float32)
        result = mask * (2 * orig_array * high_pass / 255.0) + \
                (1 - mask) * (255 - 2 * (255 - orig_array) * (255 - high_pass) / 255.0)
        
        # åº”ç”¨å¼ºåº¦
        result = orig_array * (1 - amount) + result * amount
        
        result = np.clip(result, 0, 255).astype(np.uint8)
        return Image.fromarray(result)
    
    def _blend_soft_light(self, original, blurred, amount):
        """æŸ”å…‰æ··åˆæ¨¡å¼"""
        orig_array = np.array(original, dtype=np.float32)
        blur_array = np.array(blurred, dtype=np.float32)
        
        # è®¡ç®—é«˜åå·®ä¿ç•™
        high_pass = orig_array - blur_array + 128.0
        high_pass = np.clip(high_pass, 0, 255)
        
        # æŸ”å…‰æ··åˆå…¬å¼
        mask = (orig_array < 128).astype(np.float32)
        result = mask * (2 * orig_array * high_pass / 255.0) + \
                (1 - mask) * (orig_array + (2 * high_pass - 255) * (255 - orig_array) / 255.0)
        
        # åº”ç”¨å¼ºåº¦
        result = orig_array * (1 - amount) + result * amount
        
        result = np.clip(result, 0, 255).astype(np.uint8)
        return Image.fromarray(result)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "HighPassFilterNode": HighPassFilterNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "HighPassFilterNode": "âœ¨ é«˜åå·®ä¿ç•™",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']

