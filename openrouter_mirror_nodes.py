"""
OpenRouter é•œåƒç«™èŠ‚ç‚¹
æ”¯æŒå¤šç§AIæ¨¡å‹çš„ç»Ÿä¸€APIæ¥å£
"""

import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import json
import time
import random
from typing import Optional, Tuple, Dict, Any, List

try:
    from .tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    from .utils import (
        image_to_base64, base64_to_image,
        validate_api_key, format_error_message, resize_image_for_api
    )
    from .config import DEFAULT_CONFIG
except ImportError:
    # ä¿®å¤å¯¼å…¥è·¯å¾„ï¼Œä¸ä½¿ç”¨å‰ç¼€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨comfyui_nanoåŒ…ä¸­
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    try:
        from tensor_utils import tensor_to_pil, pil_to_tensor, batch_tensor_to_pil_list, get_tensor_info
    except ImportError:
        print("âš ï¸ æ— æ³•å¯¼å…¥tensor_utilsæ¨¡å—ï¼Œä½¿ç”¨å†…ç½®ç®€åŒ–ç‰ˆæœ¬")
        # ç®€åŒ–ç‰ˆtensorè½¬æ¢å‡½æ•°
        def tensor_to_pil(tensor):
            """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
            tensor = tensor.cpu().detach().numpy()
            # å°†tensorçš„ç»´åº¦ä»[C, H, W]è½¬æ¢ä¸º[H, W, C]
            tensor = tensor.transpose(1, 2, 0)
            # ç¡®ä¿å€¼çš„èŒƒå›´æ˜¯0-1
            tensor = tensor * 255
            tensor = np.clip(tensor, 0, 255).astype(np.uint8)
            # åˆ›å»ºPILå›¾åƒ
            return Image.fromarray(tensor)
        
        def pil_to_tensor(pil_image):
            """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor"""
            # ç¡®ä¿å›¾åƒæ˜¯RGBæ¨¡å¼
            if pil_image.mode != "RGB":
                pil_image = pil_image.convert("RGB")
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            np_image = np.array(pil_image).astype(np.float32) / 255.0
            # è½¬æ¢ä¸º[C, H, W]æ ¼å¼
            np_image = np_image.transpose(2, 0, 1)
            # åˆ›å»ºtensor
            return torch.from_numpy(np_image)
        
        def batch_tensor_to_pil_list(batch_tensor):
            """å°†æ‰¹æ¬¡tensorè½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨"""
            return [tensor_to_pil(batch_tensor[i]) for i in range(batch_tensor.shape[0])]
        
        def get_tensor_info(tensor):
            """è·å–tensorçš„ä¿¡æ¯"""
            shape = tensor.shape
            return f"å½¢çŠ¶:{shape}, ç±»å‹:{tensor.dtype}, è®¾å¤‡:{tensor.device}, æœ€å°å€¼:{tensor.min().item():.4f}, æœ€å¤§å€¼:{tensor.max().item():.4f}"
    
    # Fallback utility functions - å…¶ä»–è¾…åŠ©å‡½æ•°çš„ç®€åŒ–ç‰ˆæœ¬
    def image_to_base64(image, format='JPEG'):
        buffer = io.BytesIO()
        if format.upper() == 'JPEG' and image.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            background.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
            image = background
        image.save(buffer, format=format, quality=95)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def base64_to_image(base64_string):
        """Base64å­—ç¬¦ä¸²è½¬PILå›¾åƒ"""
        image_data = base64.b64decode(base64_string)
        return Image.open(io.BytesIO(image_data))
    
    def validate_api_key(api_key):
        return api_key and len(api_key.strip()) > 10
    
    def format_error_message(error):
        return str(error)
    
    def resize_image_for_api(image, max_size=4000):
        """è°ƒæ•´å›¾åƒå¤§å°ä»¥æ»¡è¶³APIé™åˆ¶"""
        width, height = image.size
        if width <= max_size and height <= max_size:
            return image
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = min(max_size / width, max_size / height)
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    
    DEFAULT_CONFIG = {"timeout": 120, "max_retries": 3}


def smart_retry_delay(attempt, error_code=None):
    """æ™ºèƒ½é‡è¯•å»¶è¿Ÿ"""
    base_delay = 2 ** attempt
    
    if error_code == 429:
        rate_limit_delay = 60 + random.uniform(10, 30)
        return max(base_delay, rate_limit_delay)
    elif error_code in [500, 502, 503, 504]:
        return base_delay + random.uniform(1, 5)
    else:
        return base_delay


class OpenRouterMirror:
    """OpenRouter é•œåƒç«™å¤šæ¨¡å‹AIèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "åˆ†æè¿™å¼ å›¾åƒå¹¶æè¿°å…¶å†…å®¹", "multiline": True}),
                "model": ([
                    "openai/gpt-4o",
                    "openai/gpt-4o-mini", 
                    "anthropic/claude-3.5-sonnet",
                    "anthropic/claude-3-haiku",
                    "google/gemini-pro-1.5",
                    "google/gemini-flash-1.5",
                    "meta-llama/llama-3.2-90b-vision-instruct",
                    "qwen/qwen-2-vl-72b-instruct",
                    "microsoft/phi-3.5-vision-instruct"
                ], {"default": "openai/gpt-4o-mini"}),
                "max_tokens": ("INT", {"default": 6664, "min": 1, "max": 6664}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            },
            "optional": {
                "images": ("IMAGE",),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
                "site_url": ("STRING", {"default": "", "multiline": False}),
                "app_name": ("STRING", {"default": "ComfyUI", "multiline": False}),
                "mirror_url": ("STRING", {"default": "https://openrouter.ai", "multiline": False, "placeholder": "é•œåƒç«™åœ°å€ï¼Œé»˜è®¤ä¸ºOpenRouterå®˜æ–¹"}),
            }
        }
        
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("response_text", "model_info")
    FUNCTION = "process"
    CATEGORY = "Nano"

    def process(self, api_key, prompt, model, max_tokens=1024, temperature=0.7, top_p=1.0, 
                images=None, image_1=None, image_2=None, image_3=None, image_4=None, image_5=None, image_6=None, 
                site_url="", app_name="ComfyUI", mirror_url="https://openrouter.ai"):
        """å¤„ç†OpenRouter APIè¯·æ±‚"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„OpenRouter APIå¯†é’¥")
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = []
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        message_content.append({
            "type": "text",
            "text": prompt.strip()
        })
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒ
        all_images = []
        
        # å¤„ç†æ‰¹æ¬¡å›¾åƒï¼ˆå‘åå…¼å®¹ï¼‰
        if images is not None:
            batch_images = [tensor_to_pil(images[i]) for i in range(images.shape[0])]
            all_images.extend(batch_images)
            print(f"ğŸ“¥ ä»æ‰¹æ¬¡å›¾åƒæ”¶åˆ° {len(batch_images)} å¼ å›¾åƒ")
        
        # å¤„ç†6ä¸ªç‹¬ç«‹çš„å›¾åƒè¾“å…¥
        individual_images = [image_1, image_2, image_3, image_4, image_5, image_6]
        image_names = ["image_1", "image_2", "image_3", "image_4", "image_5", "image_6"]
        
        for i, img in enumerate(individual_images):
            if img is not None:
                pil_image = tensor_to_pil(img)
                all_images.append(pil_image)
                print(f"ğŸ“¥ æ”¶åˆ° {image_names[i]}: {pil_image.size}")
        
        # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if all_images:
            print(f"ğŸ“¥ æ”¶åˆ° {len(all_images)} å¼ å›¾åƒè¿›è¡Œåˆ†æ")
            
            for i, pil_image in enumerate(all_images):
                # è°ƒæ•´å›¾åƒå¤§å°ä»¥æ»¡è¶³APIé™åˆ¶
                resized_image = resize_image_for_api(pil_image, max_size=2048)
                image_base64 = image_to_base64(resized_image, format='JPEG')
                
                message_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                })
                print(f"ğŸ“ æ·»åŠ ç¬¬ {i+1} å¼ å›¾åƒåˆ°è¯·æ±‚ä¸­")
        
        # æ„å»ºAPI URL - ä½¿ç”¨å¯é…ç½®çš„é•œåƒç«™åœ°å€
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æœ«å°¾çš„æ–œæ 
        base_url = mirror_url.rstrip('/')
        url = f"{base_url}/api/v1/chat/completions"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": message_content
                }
            ],
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "stream": False
        }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key.strip()}",
            "Content-Type": "application/json",
            "HTTP-Referer": site_url if site_url else "https://github.com/comfyanonymous/ComfyUI",
            "X-Title": app_name
        }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_request_and_process(url, headers, request_data, model)
    
    def _send_request_and_process(self, url, headers, request_data, model):
        """å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ¤– æ­£åœ¨å¤„ç†è¯·æ±‚... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ ä½¿ç”¨OpenRouter API: {url}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–å“åº”æ–‡æœ¬
                    response_text = ""
                    model_info = ""
                    
                    if "choices" in result and result["choices"]:
                        choice = result["choices"][0]
                        if "message" in choice and "content" in choice["message"]:
                            response_text = choice["message"]["content"]
                    
                    # æå–æ¨¡å‹ä½¿ç”¨ä¿¡æ¯
                    if "usage" in result:
                        usage = result["usage"]
                        model_info = f"æ¨¡å‹: {model}\n"
                        model_info += f"è¾“å…¥tokens: {usage.get('prompt_tokens', 'N/A')}\n"
                        model_info += f"è¾“å‡ºtokens: {usage.get('completion_tokens', 'N/A')}\n"
                        model_info += f"æ€»tokens: {usage.get('total_tokens', 'N/A')}"
                    
                    # å¦‚æœæœ‰æ¨¡å‹IDä¿¡æ¯
                    if "model" in result:
                        model_info += f"\nå®é™…ä½¿ç”¨æ¨¡å‹: {result['model']}"
                    
                    if not response_text:
                        response_text = "è¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°æœ‰æ•ˆå“åº”"
                    
                    print(f"âœ… å¤„ç†å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
                    return (response_text, model_info)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                        
                        # æå–å…·ä½“é”™è¯¯ä¿¡æ¯
                        if "error" in error_detail:
                            error_msg = error_detail["error"].get("message", str(error_detail["error"]))
                        else:
                            error_msg = str(error_detail)
                            
                    except:
                        error_msg = response.text
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {error_msg}")
                    
                    if attempt == max_retries - 1:
                        raise ValueError(f"OpenRouter APIé”™è¯¯ ({response.status_code}): {error_msg}")
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤„ç†å¤±è´¥: {error_msg}")


class OpenRouterTextGeneration:
    """OpenRouter çº¯æ–‡æœ¬ç”ŸæˆèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "multiline": True}),
                "model": ([
                    "openai/gpt-4o",
                    "openai/gpt-4o-mini",
                    "openai/gpt-3.5-turbo",
                    "anthropic/claude-3.5-sonnet",
                    "anthropic/claude-3-haiku",
                    "google/gemini-pro-1.5",
                    "google/gemini-flash-1.5",
                    "meta-llama/llama-3.1-405b-instruct",
                    "meta-llama/llama-3.1-70b-instruct",
                    "meta-llama/llama-3.1-8b-instruct",
                    "mistralai/mistral-7b-instruct",
                    "qwen/qwen-2-72b-instruct"
                ], {"default": "openai/gpt-4o-mini"}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 6664}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            },
            "optional": {
                "system_prompt": ("STRING", {"default": "", "multiline": True}),
                "site_url": ("STRING", {"default": "", "multiline": False}),
                "app_name": ("STRING", {"default": "ComfyUI", "multiline": False}),
                "mirror_url": ("STRING", {"default": "https://openrouter.ai", "multiline": False, "placeholder": "é•œåƒç«™åœ°å€ï¼Œé»˜è®¤ä¸ºOpenRouterå®˜æ–¹"}),
            }
        }
        
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("response_text", "model_info")
    FUNCTION = "generate"
    CATEGORY = "Nano"

    def generate(self, api_key, prompt, model, max_tokens=1024, temperature=0.7, top_p=1.0,
                seed=0, system_prompt="", site_url="", app_name="ComfyUI", mirror_url="https://openrouter.ai"):
        """ç”Ÿæˆæ–‡æœ¬å“åº”"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„OpenRouter APIå¯†é’¥")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if system_prompt.strip():
            messages.append({
                "role": "system",
                "content": system_prompt.strip()
            })
        
        # æ·»åŠ ç”¨æˆ·æç¤º
        messages.append({
            "role": "user", 
            "content": prompt.strip()
        })
        
        # æ„å»ºAPI URL - ä½¿ç”¨å¯é…ç½®çš„é•œåƒç«™åœ°å€
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æœ«å°¾çš„æ–œæ 
        base_url = mirror_url.rstrip('/')
        url = f"{base_url}/api/v1/chat/completions"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "stream": False
        }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key.strip()}",
            "Content-Type": "application/json",
            "HTTP-Referer": site_url if site_url else "https://github.com/comfyanonymous/ComfyUI",
            "X-Title": app_name
        }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_request_and_process(url, headers, request_data, model)
    
    def _send_request_and_process(self, url, headers, request_data, model):
        """å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ’¬ æ­£åœ¨ç”Ÿæˆæ–‡æœ¬... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ ä½¿ç”¨OpenRouter API: {url}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–å“åº”æ–‡æœ¬
                    response_text = ""
                    model_info = ""
                    
                    if "choices" in result and result["choices"]:
                        choice = result["choices"][0]
                        if "message" in choice and "content" in choice["message"]:
                            response_text = choice["message"]["content"]
                    
                    # æå–æ¨¡å‹ä½¿ç”¨ä¿¡æ¯
                    if "usage" in result:
                        usage = result["usage"]
                        model_info = f"æ¨¡å‹: {model}\n"
                        model_info += f"è¾“å…¥tokens: {usage.get('prompt_tokens', 'N/A')}\n"
                        model_info += f"è¾“å‡ºtokens: {usage.get('completion_tokens', 'N/A')}\n"
                        model_info += f"æ€»tokens: {usage.get('total_tokens', 'N/A')}"
                    
                    # å¦‚æœæœ‰æ¨¡å‹IDä¿¡æ¯
                    if "model" in result:
                        model_info += f"\nå®é™…ä½¿ç”¨æ¨¡å‹: {result['model']}"
                    
                    if not response_text:
                        response_text = "è¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°æœ‰æ•ˆå“åº”"
                    
                    print(f"âœ… æ–‡æœ¬ç”Ÿæˆå®Œæˆï¼Œå“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
                    return (response_text, model_info)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                        
                        # æå–å…·ä½“é”™è¯¯ä¿¡æ¯
                        if "error" in error_detail:
                            error_msg = error_detail["error"].get("message", str(error_detail["error"]))
                        else:
                            error_msg = str(error_detail)
                            
                    except:
                        error_msg = response.text
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {error_msg}")
                    
                    if attempt == max_retries - 1:
                        raise ValueError(f"OpenRouter APIé”™è¯¯ ({response.status_code}): {error_msg}")
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤„ç†å¤±è´¥: {error_msg}")


class OpenRouterImageEdit:
    """OpenRouter å›¾åƒç¼–è¾‘èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "ç¼–è¾‘è¿™å¼ å›¾åƒï¼Œè®©å®ƒæ›´åŠ ç¾è§‚", "multiline": True}),
                "model": ([
                    "openai/gpt-4o",
                    "openai/gpt-4o-mini",
                    "google/gemini-2.5-flash-image-preview",
                    "google/gemini-2.5-flash-image",
                ], {"default": "openai/gpt-4o-mini"}),
                "aspectRatio": ([
                    "auto",     # è‡ªåŠ¨é€‰æ‹©æœ€ä½³é•¿å®½æ¯”
                    "1:1",      # æ­£æ–¹å½¢
                    "9:16",     # ç«–å±
                    "16:9",     # æ¨ªå±
                    "3:4",      # ç«–å±
                    "4:3",      # æ¨ªå±
                    "3:2",      # æ¨ªå±
                    "2:3",      # ç«–å±
                    "5:4",      # æ¨ªå±
                    "4:5",      # ç«–å±
                    "21:9",     # è¶…å®½å±
                ], {"default": "auto"}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_tokens": ("INT", {"default": 6664, "min": 1, "max": 6664}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            },
            "optional": {
                "images": ("IMAGE",),
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
                "system_instruction": ("STRING", {"default": "", "multiline": True, "placeholder": "å¯é€‰ï¼šç³»ç»Ÿæç¤ºè¯ï¼Œä¸ºç©ºæ—¶ä¸å‘é€"}),
                "site_url": ("STRING", {"default": "https://github.com/comfyanonymous/ComfyUI", "multiline": False}),
                "app_name": ("STRING", {"default": "ComfyUI", "multiline": False}),
                "mirror_url": ("STRING", {"default": "https://openrouter.ai", "multiline": False, "placeholder": "é•œåƒç«™åœ°å€ï¼Œé»˜è®¤ä¸ºOpenRouterå®˜æ–¹"}),
            }
        }
        
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("edited_image", "edit_description")
    FUNCTION = "edit_image"
    CATEGORY = "Nano"

    def edit_image(self, api_key, prompt, model, aspectRatio="auto", temperature=0.7, top_p=1.0, max_tokens=6664,
                   seed=0, images=None, image_1=None, image_2=None, image_3=None, image_4=None, image_5=None, image_6=None,
                   system_instruction="", site_url="https://github.com/comfyanonymous/ComfyUI", app_name="ComfyUI", mirror_url="https://openrouter.ai"):
        """ç¼–è¾‘å›¾åƒ"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„OpenRouter APIå¯†é’¥")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒ
        all_images = []
        
        # å¤„ç†æ‰¹æ¬¡å›¾åƒï¼ˆå‘åå…¼å®¹ï¼‰
        if images is not None:
            batch_images = [tensor_to_pil(images[i]) for i in range(images.shape[0])]
            all_images.extend(batch_images)
            print(f"ğŸ“¥ ä»æ‰¹æ¬¡å›¾åƒæ”¶åˆ° {len(batch_images)} å¼ å›¾åƒ")
        
        # å¤„ç†6ä¸ªç‹¬ç«‹çš„å›¾åƒè¾“å…¥
        individual_images = [image_1, image_2, image_3, image_4, image_5, image_6]
        image_names = ["image_1", "image_2", "image_3", "image_4", "image_5", "image_6"]
        
        for i, img in enumerate(individual_images):
            if img is not None:
                pil_image = tensor_to_pil(img)
                all_images.append(pil_image)
                print(f"ğŸ“¥ æ”¶åˆ° {image_names[i]}: {pil_image.size}")
        
        if not all_images:
            raise ValueError("è¯·è‡³å°‘æä¾›ä¸€å¼ å›¾åƒ")
        
        print(f"ğŸ“¥ æ€»å…±æ”¶åˆ° {len(all_images)} å¼ å›¾åƒè¿›è¡Œç¼–è¾‘")
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = [{"type": "text", "text": prompt.strip()}]
        
        # æ·»åŠ å›¾åƒåˆ°æ¶ˆæ¯ä¸­
        for i, pil_image in enumerate(all_images):
            resized_image = resize_image_for_api(pil_image, max_size=2048)
            image_base64 = image_to_base64(resized_image, format='JPEG')
            
            message_content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image_base64}"
                }
            })
            print(f"ğŸ“ æ·»åŠ ç¬¬ {i+1} å¼ å›¾åƒåˆ°ç¼–è¾‘è¯·æ±‚ä¸­")
        
        # æ„å»ºAPI URL - ä½¿ç”¨å¯é…ç½®çš„é•œåƒç«™åœ°å€
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æœ«å°¾çš„æ–œæ 
        base_url = mirror_url.rstrip('/')
        url = f"{base_url}/api/v1/chat/completions"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": message_content
                }
            ],
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "stream": False
        }
        
        # å¦‚æœæ˜¯æ”¯æŒå›¾åƒç”Ÿæˆçš„æ¨¡å‹ï¼Œæ·»åŠ modalitieså‚æ•°
        if any(gen_model in model for gen_model in ["gemini", "gpt-4o"]):
            request_data["modalities"] = ["image", "text"]
        
        # åªæœ‰å½“é•¿å®½æ¯”ä¸æ˜¯ "auto" æ—¶æ‰æ·»åŠ  imageConfig åˆ° generationConfig
        if aspectRatio != "auto":
            request_data["generationConfig"] = {
                "imageConfig": {
                    "aspectRatio": aspectRatio
                }
            }
        
        # åªæœ‰å½“ç³»ç»Ÿæç¤ºè¯ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ  systemInstruction
        if system_instruction and system_instruction.strip():
            request_data["systemInstruction"] = {
                "parts": [
                    {"text": system_instruction.strip()}
                ]
            }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key.strip()}",
            "Content-Type": "application/json",
            "HTTP-Referer": site_url,
            "X-Title": app_name
        }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_edit_request_and_process(url, headers, request_data, model, all_images[0])
    
    def _send_edit_request_and_process(self, url, headers, request_data, model, fallback_image):
        """å‘é€ç¼–è¾‘è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 120)
        
        for attempt in range(max_retries):
            try:
                print(f"âœï¸ æ­£åœ¨ç¼–è¾‘å›¾åƒ... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ ä½¿ç”¨OpenRouter API: {url}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–ç¼–è¾‘ç»“æœ
                    edited_image = None
                    edit_description = ""
                    
                    if "choices" in result and result["choices"]:
                        choice = result["choices"][0]
                        message = choice.get("message", {})
                        
                        # æå–æ–‡æœ¬æè¿°
                        if "content" in message:
                            edit_description = message["content"]
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„å›¾åƒ
                        if "images" in message and message["images"]:
                            for image_item in message["images"]:
                                if "image_url" in image_item:
                                    image_url = image_item["image_url"]["url"]
                                    
                                    # å¤„ç†base64æ•°æ®URL
                                    if image_url.startswith("data:image/"):
                                        try:
                                            base64_data = image_url.split(",")[1]
                                            pil_image = base64_to_image(base64_data)
                                            edited_image = pil_to_tensor(pil_image)
                                            print("âœ… æˆåŠŸè·å–ç¼–è¾‘åçš„å›¾åƒ")
                                            break
                                        except Exception as e:
                                            print(f"âš ï¸ è§£ç ç¼–è¾‘å›¾åƒå¤±è´¥: {e}")
                                    
                                    # å¤„ç†URL
                                    elif image_url.startswith("http"):
                                        try:
                                            img_response = requests.get(image_url, timeout=30)
                                            img_response.raise_for_status()
                                            pil_image = Image.open(io.BytesIO(img_response.content))
                                            edited_image = pil_to_tensor(pil_image)
                                            print("âœ… æˆåŠŸä»URLè·å–ç¼–è¾‘å›¾åƒ")
                                            break
                                        except Exception as e:
                                            print(f"âš ï¸ ä»URLè·å–ç¼–è¾‘å›¾åƒå¤±è´¥: {e}")
                    
                    # å¦‚æœæ²¡æœ‰ç¼–è¾‘åçš„å›¾åƒï¼Œè¿”å›åŸå›¾åƒ
                    if edited_image is None:
                        print("âš ï¸ æœªæ”¶åˆ°ç¼–è¾‘åçš„å›¾åƒï¼Œè¿”å›åŸå›¾åƒ")
                        edited_image = pil_to_tensor(fallback_image)
                        if not edit_description:
                            edit_description = "å›¾åƒç¼–è¾‘è¯·æ±‚å·²å¤„ç†ï¼Œä½†æœªç”Ÿæˆæ–°å›¾åƒ"
                    
                    if not edit_description:
                        edit_description = "å›¾åƒç¼–è¾‘å®Œæˆ"
                    
                    print(f"âœ… å›¾åƒç¼–è¾‘å®Œæˆï¼Œè¾“å‡ºå¼ é‡å½¢çŠ¶: {edited_image.shape}")
                    return (edited_image, edit_description)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                        
                        if "error" in error_detail:
                            error_msg = error_detail["error"].get("message", str(error_detail["error"]))
                        else:
                            error_msg = str(error_detail)
                            
                    except:
                        error_msg = response.text
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {error_msg}")
                    
                    if attempt == max_retries - 1:
                        raise ValueError(f"OpenRouter å›¾åƒç¼–è¾‘é”™è¯¯ ({response.status_code}): {error_msg}")
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤„ç†å¤±è´¥: {error_msg}")


class OpenRouterMultimodalImageGeneration:
    """OpenRouter å¤šæ¨¡æ€å›¾åƒç”ŸæˆèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "prompt": ("STRING", {"default": "Generate a beautiful landscape painting", "multiline": True}),
                "model": ([
                    "google/gemini-2.5-flash-image",
                    "google/gemini-2.5-flash-image-preview",
                    "google/gemini-2.0-flash-preview-image-generation",
                    "openai/gpt-4o",
                    "openai/gpt-4o-mini",
                    "anthropic/claude-3.5-sonnet",
                    "meta-llama/llama-3.2-90b-vision-instruct"
                ], {"default": "openai/gpt-4o-mini"}),
                "aspect_ratio": ([
                    "auto",     # è‡ªåŠ¨é€‰æ‹©æœ€ä½³é•¿å®½æ¯”
                    "1:1",      # æ­£æ–¹å½¢
                    "9:16",     # ç«–å±
                    "16:9",     # æ¨ªå±
                    "3:4",      # ç«–å±
                    "4:3",      # æ¨ªå±
                    "3:2",      # æ¨ªå±
                    "2:3",      # ç«–å±
                    "5:4",      # æ¨ªå±
                    "4:5",      # ç«–å±
                    "21:9",     # è¶…å®½å±
                ], {"default": "auto"}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.05}),
                "max_output_tokens": ("INT", {"default": 6664, "min": 1, "max": 32768}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
            },
            "optional": {
                "site_url": ("STRING", {"default": "", "multiline": False}),
                "app_name": ("STRING", {"default": "ComfyUI", "multiline": False}),
                "system_instruction": ("STRING", {"default": "", "multiline": True, "placeholder": "å¯é€‰ï¼šç³»ç»Ÿæç¤ºè¯ï¼Œä¸ºç©ºæ—¶ä¸å‘é€"}),
                "mirror_url": ("STRING", {"default": "https://openrouter.ai", "multiline": False, "placeholder": "é•œåƒç«™åœ°å€ï¼Œé»˜è®¤ä¸ºOpenRouterå®˜æ–¹"}),
            }
        }
        
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("generated_image", "response_text")
    FUNCTION = "generate_image"
    CATEGORY = "Nano"

    def generate_image(self, api_key, prompt, model, aspect_ratio="auto", temperature=1.0, top_p=0.95, max_output_tokens=6664,
                      seed=0, site_url="", app_name="ComfyUI", system_instruction="", mirror_url="https://openrouter.ai"):
        """ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ç”Ÿæˆå›¾åƒ"""
        
        # æ£€æŸ¥APIå¯†é’¥
        if not validate_api_key(api_key):
            raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„OpenRouter APIå¯†é’¥")
        
        # æ„å»ºAPI URL - ä½¿ç”¨å¯é…ç½®çš„é•œåƒç«™åœ°å€
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®ï¼Œç§»é™¤æœ«å°¾çš„æ–œæ 
        base_url = mirror_url.rstrip('/')
        url = f"{base_url}/api/v1/chat/completions"
        
        # æ„å»ºè¯·æ±‚æ•°æ® - ä½¿ç”¨Geminiçš„å¤šæ¨¡æ€æ ¼å¼
        request_data = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt.strip()
                }
            ],
            "modalities": ["image", "text"],
            "temperature": temperature,
            "top_p": top_p,
            "max_tokens": max_output_tokens
        }
        
        # åªæœ‰å½“é•¿å®½æ¯”ä¸æ˜¯ "auto" æ—¶æ‰æ·»åŠ  imageConfig åˆ° generationConfig
        if aspect_ratio != "auto":
            request_data["generationConfig"] = {
                "imageConfig": {
                    "aspectRatio": aspect_ratio
                }
            }
        
        # åªæœ‰å½“ç³»ç»Ÿæç¤ºè¯ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ  systemInstruction
        if system_instruction and system_instruction.strip():
            request_data["systemInstruction"] = {
                "parts": [
                    {"text": system_instruction.strip()}
                ]
            }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key.strip()}",
            "Content-Type": "application/json",
            "HTTP-Referer": site_url if site_url else "https://github.com/comfyanonymous/ComfyUI",
            "X-Title": app_name
        }
        
        # å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”
        return self._send_request_and_process(url, headers, request_data, model)
    
    def _send_request_and_process(self, url, headers, request_data, model):
        """å‘é€è¯·æ±‚å¹¶å¤„ç†å“åº”"""
        
        max_retries = 5
        timeout = DEFAULT_CONFIG.get("timeout", 180)  # å›¾åƒç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾åƒ... (å°è¯• {attempt + 1}/{max_retries}) ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ ä½¿ç”¨OpenRouter API: {url}")
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=request_data, timeout=timeout)
                
                # æˆåŠŸå“åº”
                if response.status_code == 200:
                    result = response.json()
                    print(f"ğŸ“‹ APIå“åº”ç»“æ„: {list(result.keys())}")
                    
                    # æå–ç”Ÿæˆçš„å›¾åƒå’Œæ–‡æœ¬
                    generated_image = None
                    response_text = ""
                    
                    if "choices" in result and result["choices"]:
                        choice = result["choices"][0]
                        message = choice.get("message", {})
                        
                        # æå–æ–‡æœ¬å“åº”
                        if "content" in message:
                            response_text = message["content"]
                        
                        # æå–å›¾åƒ
                        if "images" in message and message["images"]:
                            for image_item in message["images"]:
                                if "image_url" in image_item:
                                    image_url = image_item["image_url"]["url"]
                                    
                                    # å¤„ç†base64æ•°æ®URL
                                    if image_url.startswith("data:image/"):
                                        try:
                                            # æå–base64æ•°æ®
                                            base64_data = image_url.split(",")[1]
                                            pil_image = base64_to_image(base64_data)
                                            generated_image = pil_to_tensor(pil_image)
                                            print("âœ… æˆåŠŸä»base64æ•°æ®ç”Ÿæˆå›¾åƒ")
                                            break
                                        except Exception as e:
                                            print(f"âš ï¸ è§£ç base64å›¾åƒå¤±è´¥: {e}")
                                    
                                    # å¤„ç†URL
                                    elif image_url.startswith("http"):
                                        try:
                                            img_response = requests.get(image_url, timeout=30)
                                            img_response.raise_for_status()
                                            pil_image = Image.open(io.BytesIO(img_response.content))
                                            generated_image = pil_to_tensor(pil_image)
                                            print("âœ… æˆåŠŸä»URLè·å–å›¾åƒ")
                                            break
                                        except Exception as e:
                                            print(f"âš ï¸ ä»URLè·å–å›¾åƒå¤±è´¥: {e}")
                    
                    # å¦‚æœæ²¡æœ‰ç”Ÿæˆå›¾åƒï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤å›¾åƒ
                    if generated_image is None:
                        print("âš ï¸ æœªèƒ½è·å–ç”Ÿæˆçš„å›¾åƒï¼Œåˆ›å»ºé»˜è®¤å›¾åƒ")
                        default_image = Image.new('RGB', (512, 512), (128, 128, 128))
                        generated_image = pil_to_tensor(default_image)
                        if not response_text:
                            response_text = "å›¾åƒç”Ÿæˆè¯·æ±‚å·²å‘é€ï¼Œä½†æœªæ”¶åˆ°å›¾åƒæ•°æ®"
                    
                    if not response_text:
                        response_text = "å›¾åƒå·²ç”Ÿæˆ"
                    
                    print(f"âœ… å›¾åƒç”Ÿæˆå®Œæˆï¼Œè¾“å‡ºå¼ é‡å½¢çŠ¶: {generated_image.shape}")
                    return (generated_image, response_text)
                
                # å¤„ç†é”™è¯¯å“åº”
                else:
                    print(f"âŒ HTTPçŠ¶æ€ç : {response.status_code}")
                    try:
                        error_detail = response.json()
                        print(f"âŒ é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                        
                        # æå–å…·ä½“é”™è¯¯ä¿¡æ¯
                        if "error" in error_detail:
                            error_msg = error_detail["error"].get("message", str(error_detail["error"]))
                        else:
                            error_msg = str(error_detail)
                            
                    except:
                        error_msg = response.text
                        print(f"âŒ é”™è¯¯æ–‡æœ¬: {error_msg}")
                    
                    if attempt == max_retries - 1:
                        raise ValueError(f"OpenRouter å›¾åƒç”Ÿæˆé”™è¯¯ ({response.status_code}): {error_msg}")
                    
                    delay = smart_retry_delay(attempt, response.status_code)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except requests.exceptions.RequestException as e:
                error_msg = format_error_message(e)
                print(f"âŒ è¯·æ±‚å¤±è´¥: {error_msg}")
                if attempt == max_retries - 1:
                    raise ValueError(f"APIè¯·æ±‚å¤±è´¥: {error_msg}")
                else:
                    delay = smart_retry_delay(attempt)
                    print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    
            except Exception as e:
                error_msg = format_error_message(e)
                print(f"âŒ å¤„ç†å¤±è´¥: {error_msg}")
                raise ValueError(f"å¤„ç†å¤±è´¥: {error_msg}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "OpenRouterMirror": OpenRouterMirror,
    "OpenRouterImageEdit": OpenRouterImageEdit,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "OpenRouterMirror": "OpenRouter è§†è§‰åˆ†æ",
    "OpenRouterImageEdit": "OpenRouter å›¾åƒç¼–è¾‘",
}
